{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random forest.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP475dYtytnGH4XSopQgCBz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahGoddaer/Machine_Learning_course_UGent_D012554_kaggle/blob/master/5%3A%20Random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThscWYOPVL2a",
        "colab_type": "code",
        "outputId": "c416fe67-05ee-459d-aae7-1c596de2240c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzCGOEn2VC7_",
        "colab_type": "text"
      },
      "source": [
        "## Decision trees\n",
        "\n",
        "Next I will try to fit a decision tree model to do predictions on the testset. An advantage about this kind of modelling is that this doesn't need scaling the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfvqs5yLVE5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/eeg_train.csv\")\n",
        "testset = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/eeg_test.csv\")\n",
        "\n",
        "features = trainset.copy()\n",
        "features.pop('label')\n",
        "feature_names = list(features.columns)\n",
        "\n",
        "test_features = testset.copy()\n",
        "test_features.pop('index')\n",
        "test_feature_names = list(test_features.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UhMwxxZVHSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model =  DecisionTreeClassifier(criterion='entropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoIKj4y2VOPH",
        "colab_type": "code",
        "outputId": "260bfffb-f557-4e82-d53c-0e57ffb5bae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "score_train = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.7532918712276511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UcPcr33WqpR",
        "colab_type": "text"
      },
      "source": [
        "From what I've seen in the SVM model is this not a score that I'm very happy with.. But who knows, maybe I can optimize it a bit more..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxjtYBZvVWFz",
        "colab_type": "code",
        "outputId": "5ca2ae00-9cc3-47ed-e44c-cedfc92a33b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "search_space = {'max_depth':[4,6,7,8,9,10], 'splitter':['best','random']}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid=search_space, scoring='roc_auc', cv=10)\n",
        "grid_search.fit(features, trainset.label)\n",
        "\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "means = grid_search.cv_results_['mean_test_score']\n",
        "stds = grid_search.cv_results_['std_test_score']\n",
        "\n",
        "for mean_score, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
        "    print(\"{:.3f} (+/-{:.3f}) for {}\".format(mean_score, std * 2, params))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 8, 'splitter': 'best'}\n",
            "0.736 (+/-0.056) for {'max_depth': 4, 'splitter': 'best'}\n",
            "0.670 (+/-0.086) for {'max_depth': 4, 'splitter': 'random'}\n",
            "0.778 (+/-0.051) for {'max_depth': 6, 'splitter': 'best'}\n",
            "0.727 (+/-0.084) for {'max_depth': 6, 'splitter': 'random'}\n",
            "0.785 (+/-0.044) for {'max_depth': 7, 'splitter': 'best'}\n",
            "0.761 (+/-0.060) for {'max_depth': 7, 'splitter': 'random'}\n",
            "0.796 (+/-0.050) for {'max_depth': 8, 'splitter': 'best'}\n",
            "0.756 (+/-0.074) for {'max_depth': 8, 'splitter': 'random'}\n",
            "0.793 (+/-0.062) for {'max_depth': 9, 'splitter': 'best'}\n",
            "0.770 (+/-0.069) for {'max_depth': 9, 'splitter': 'random'}\n",
            "0.783 (+/-0.074) for {'max_depth': 10, 'splitter': 'best'}\n",
            "0.789 (+/-0.040) for {'max_depth': 10, 'splitter': 'random'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUYpPOYVVc5-",
        "colab_type": "code",
        "outputId": "cbef0fb6-69bc-45c8-b3fe-98c491e788b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model = DecisionTreeClassifier(max_depth=8, criterion = 'entropy') \n",
        "score_train = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.7987575340052404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGzbBzHcW4xu",
        "colab_type": "text"
      },
      "source": [
        "This is an increase of 4.5%, so I think this is not bad, but the actual AUC score doesn't even come close to what I found with the SVM model. I'm going again to a more complicated model:\n",
        "\n",
        "#Random forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGO878sTVlkm",
        "colab_type": "code",
        "outputId": "f1bd7e18-42ea-4ff1-f4ec-e9be7b4caaf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(criterion='entropy')\n",
        "\n",
        "score_train = cross_val_score(rf, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score_train))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9285521298273591\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U7cNN_TXUm9",
        "colab_type": "text"
      },
      "source": [
        "Waaaw, this is a high score immediatly without optimizing it's parameters. This is a model that is known for it's good performance, without optimizing it's parameters. I'm going to try to lift the score, maybe it will be higher than the SVM model, we'll see...\n",
        "\n",
        "First I want to know which parameters are included:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STBqYJx3VqUN",
        "colab_type": "code",
        "outputId": "462bf0a2-7a69-424d-b4a3-af3d9170e479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "print(rf.get_params())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ra0n3bgVsf2",
        "colab_type": "code",
        "outputId": "9201a662-c284-4cf0-82e6-7dae9ca1925a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "search_space = {'max_depth': [2,3,5,10,15, 20, 30],\n",
        "                'n_estimators': [200, 250, 300, 400]}\n",
        "\n",
        "grid_search = GridSearchCV(rf,search_space, scoring='roc_auc')\n",
        "grid_search.fit(features,trainset.label)\n",
        "\n",
        "print(grid_search.best_estimator_)\n",
        "print(grid_search.best_params_)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='entropy', max_depth=30, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=250,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "{'max_depth': 30, 'n_estimators': 250}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2BZr0EyVvU5",
        "colab_type": "code",
        "outputId": "507f2761-8483-4b43-c9f8-39098d5890ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "model = RandomForestClassifier(criterion='entropy',n_estimators=250, max_depth=20, bootstrap=False)\n",
        "\n",
        "score_train = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score_train))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9365576253512036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lH6EYd3X6_3",
        "colab_type": "text"
      },
      "source": [
        "OK, i was able to higher the score a little bit, but not so much as I expected. Maybe I should do it's tuning better or maybe it's already so good without changing its parameters that this doesn't matter so much."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbFiCxiXYqkU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6b37558b-e932-48e4-8072-6f69df6af220"
      },
      "source": [
        "model = RandomForestClassifier(criterion='entropy',n_estimators=250, max_depth=20, bootstrap=True)\n",
        "\n",
        "score_train = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score_train))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9308660737835049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kH-QZa5WHui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3f9ec96e-0175-4509-dc9c-a61e84759cb2"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "clf = BaggingClassifier(base_estimator=RandomForestClassifier(\n",
        "    criterion='entropy',n_estimators=250, max_depth=20, \n",
        "    bootstrap=True), n_estimators=100, random_state=0)\n",
        "\n",
        "score_train = cross_val_score(clf, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score_train))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9211703230510571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEAT_nnjmohT",
        "colab_type": "text"
      },
      "source": [
        "This last score suggests that bagging is not the way to improve this model."
      ]
    }
  ]
}