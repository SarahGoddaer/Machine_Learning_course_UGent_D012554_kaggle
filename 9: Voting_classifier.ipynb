{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voting classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZvwaGl66T8acUdawlqdh4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahGoddaer/Machine_Learning_course_UGent_D012554_kaggle/blob/master/9%3A%20Voting_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpjI-lJ-B5Tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTTJWQkOBs0y",
        "colab_type": "text"
      },
      "source": [
        "Here, I want to know if combining the different results of the different models I used can make an improvement towards predicting test set labels.\n",
        "\n",
        "#Voting classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqnwx_xtDWzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/eeg_train.csv\")\n",
        "testset = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/eeg_test.csv\")\n",
        "\n",
        "features = trainset.copy()\n",
        "features.pop('label')\n",
        "feature_names = list(features.columns)\n",
        "\n",
        "test_features = testset.copy()\n",
        "test_features.pop('index')\n",
        "test_feature_names = list(test_features.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZS7W0mfB6St",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Training classifiers\n",
        "clf1 = make_pipeline(StandardScaler(), SVC(C=10,gamma=1, probability=True))\n",
        "clf2 = RandomForestClassifier(criterion='entropy', n_estimators=250, \n",
        "                              max_depth=30, random_state=0)\n",
        "clf3 = XGBClassifier(n_estimators= 900, gamma=0, max_depth=7, \n",
        "                     min_child_weight=0, learning_rate=0.1, \n",
        "                     subsample=0.85, colsample_bytree=0.9)\n",
        "clf4 = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
        "clf5 = make_pipeline(StandardScaler(),LogisticRegression(C=100))\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), \n",
        "                                    ('xgb', clf3), ('kkn', clf4), \n",
        "                                    ('reg', clf5)], voting='soft')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__XhgAmzFTNu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "92cb9ccc-5db7-4082-b77c-086cd10605b6"
      },
      "source": [
        "for clf, name in zip([clf1, clf2, clf3, clf4, clf5, eclf], \n",
        "                      ['SVC', 'Random Forest', 'XGBoost', 'KNeighbors', \n",
        "                       'Logistic regression', 'Ensemble']):\n",
        "  scores = cross_val_score(clf, features, trainset.label, \n",
        "                           scoring='roc_auc', cv=10)\n",
        "  print(\"AUC score: %0.5f (+/- %0.5f) [%s]\" % (scores.mean(), scores.std(), name))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score: 0.96253 (+/- 0.01182) [SVC]\n",
            "AUC score: 0.93205 (+/- 0.01971) [Random Forest]\n",
            "AUC score: 0.94602 (+/- 0.02002) [XGBoost]\n",
            "AUC score: 0.95938 (+/- 0.01119) [KNeighbors]\n",
            "AUC score: 0.65963 (+/- 0.03643) [Logistic regression]\n",
            "AUC score: 0.96706 (+/- 0.01412) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3IXBDgvJpcQ",
        "colab_type": "text"
      },
      "source": [
        "Ok, this seems to work! Now I will see if this approach maybe better works without the logistic regression model..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1332hI_GXoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Training classifiers\n",
        "clf1 = make_pipeline(StandardScaler(), SVC(C=10,gamma=1, probability=True))\n",
        "clf2 = RandomForestClassifier(criterion='entropy', n_estimators=250, \n",
        "                              max_depth=30, random_state=0)\n",
        "clf3 = XGBClassifier(n_estimators= 900, gamma=0, max_depth=7, \n",
        "                     min_child_weight=0, learning_rate=0.1, \n",
        "                     subsample=0.85, colsample_bytree=0.9)\n",
        "clf4 = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), \n",
        "                                    ('xgb', clf3), ('kkn', clf4)],\n",
        "                        voting='soft')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyjmfXH0KSoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "69a09b05-777e-48ad-b72a-51ad5bbff6ec"
      },
      "source": [
        "for clf, name in zip([clf1, clf2, clf3, clf4, eclf], \n",
        "                      ['SVC', 'Random Forest', 'XGBoost', 'KNeighbors', \n",
        "                       'Ensemble']):\n",
        "  scores = cross_val_score(clf, features, trainset.label, \n",
        "                           scoring='roc_auc', cv=10)\n",
        "  print(\"AUC score: %0.5f (+/- %0.5f) [%s]\" % (scores.mean(), scores.std(), name))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score: 0.96253 (+/- 0.01182) [SVC]\n",
            "AUC score: 0.93205 (+/- 0.01971) [Random Forest]\n",
            "AUC score: 0.94602 (+/- 0.02002) [XGBoost]\n",
            "AUC score: 0.95938 (+/- 0.01119) [KNeighbors]\n",
            "AUC score: 0.96951 (+/- 0.01216) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_K6WDD7d6Dn",
        "colab_type": "text"
      },
      "source": [
        "So it seems to be that this also gives a better outcome on the trainset if you compare the AUC score. This is almost as good as what I achieved with stacking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t02DHpq6eG56",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0ade9e65-f21a-4a33-f0b9-8b4433680747"
      },
      "source": [
        "score = cross_val_score(eclf, features, trainset.label, scoring = 'roc_auc', cv=10).mean()\n",
        "print('AUC score: ' + str(score))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score: 0.9694883699379112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-55cxdtyho7T",
        "colab_type": "text"
      },
      "source": [
        "I put some weights in it, just to try and see what influence this has on the AUC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra0j7dS4hyLY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "84b636bd-813c-447b-c9e6-85e95b5d68a7"
      },
      "source": [
        "votingClass = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), \n",
        "                                    ('xgb', clf3), ('kkn', clf4)],\n",
        "                        voting='soft', weights=[2,1, 1, 2])\n",
        "\n",
        "for clf, name in zip([clf1, clf2, clf3, clf4, votingClass], \n",
        "                      ['SVC', 'Random Forest', 'XGBoost', 'KNeighbors', \n",
        "                       'Ensemble']):\n",
        "  scores = cross_val_score(clf, features, trainset.label, \n",
        "                           scoring='roc_auc', cv=10)\n",
        "  print(\"AUC score: %0.5f (+/- %0.5f) [%s]\" % (scores.mean(), scores.std(), name))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score: 0.96253 (+/- 0.01182) [SVC]\n",
            "AUC score: 0.93205 (+/- 0.01971) [Random Forest]\n",
            "AUC score: 0.94602 (+/- 0.02002) [XGBoost]\n",
            "AUC score: 0.95938 (+/- 0.01119) [KNeighbors]\n",
            "AUC score: 0.97152 (+/- 0.01101) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGwejGHci76-",
        "colab_type": "text"
      },
      "source": [
        "Well I think this was luck with choosing my weights... But this score is the same as with the stacking technique, apart from a tiny difference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsKzfG1yiTst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "64aa8ad5-ed1a-4305-9652-5645c26a599b"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "vc = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), \n",
        "                                    ('xgb', clf3), ('kkn', clf4)],\n",
        "                        voting='soft')\n",
        "\n",
        "params = {'weights':[[2,1,1,2],[3,1,2,3],[3,1,2,2]]}\n",
        "grid_Search = GridSearchCV(param_grid = params, estimator=vc, scoring='roc_auc', cv=10)\n",
        "grid_Search.fit(features, trainset.label)\n",
        "print(grid_Search.best_params_)\n",
        "print(grid_Search.best_score_)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'weights': [2, 1, 1, 2]}\n",
            "0.9715493629713814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrKYAZTklBIG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bace8c37-e49a-4b01-d76f-1484f412c3b2"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "vc = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), \n",
        "                                    ('xgb', clf3), ('kkn', clf4)],\n",
        "                        voting='soft')\n",
        "\n",
        "params = {'weights':[[2,1,1,2],[3,3,1,3],[2,2,1,2]]}\n",
        "grid_Search = GridSearchCV(param_grid = params, estimator=vc, scoring='roc_auc', cv=10)\n",
        "grid_Search.fit(features, trainset.label)\n",
        "print(grid_Search.best_params_)\n",
        "print(grid_Search.best_score_)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'weights': [2, 1, 1, 2]}\n",
            "0.9715089976282636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H98j249uzP_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5f2cda6b-d8e9-4b3c-f395-f010da597d8e"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "vc = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), \n",
        "                                    ('xgb', clf3), ('kkn', clf4)],\n",
        "                        voting='soft')\n",
        "\n",
        "params = {'weights':[[2,1,1,2],[3,1,1,3],[2,1,2,3], [3,1,3,3]]}\n",
        "grid_Search = GridSearchCV(param_grid = params, estimator=vc, scoring='roc_auc', cv=10)\n",
        "grid_Search.fit(features, trainset.label)\n",
        "print(grid_Search.best_params_)\n",
        "print(grid_Search.best_score_)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'weights': [3, 1, 1, 3]}\n",
            "0.9718729435701912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW8Ge4B41B3N",
        "colab_type": "text"
      },
      "source": [
        "This is the best score I have 'till now! Maybe I could tune those weights a bit more, we will see.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ub8IURK1M5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "142e9d1b-56f8-4a22-9b15-27c11ff215bd"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "vc = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), \n",
        "                                    ('xgb', clf3), ('kkn', clf4)],\n",
        "                        voting='soft')\n",
        "\n",
        "params = {'weights':[[3,1,1,3],[4,1,1,4],[2,1,2,3], [3,1,3,3]]}\n",
        "grid_Search = GridSearchCV(param_grid = params, estimator=vc, scoring='roc_auc', cv=10)\n",
        "grid_Search.fit(features, trainset.label)\n",
        "print(grid_Search.best_params_)\n",
        "print(grid_Search.best_score_)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'weights': [3, 1, 1, 3]}\n",
            "0.9719032272518513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc1XDE_99dma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9315cc88-60c0-4c73-8ea4-097c3dfca83e"
      },
      "source": [
        "params = {'weights':[[3,1,1,3],[3,1,1,2],[2,1,1,3], [3,1,1,4],[4,1,1,3]]}\n",
        "grid_Search = GridSearchCV(param_grid = params, estimator=vc, scoring='roc_auc', cv=10)\n",
        "grid_Search.fit(features, trainset.label)\n",
        "print(grid_Search.best_params_)\n",
        "print(grid_Search.best_score_)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'weights': [4, 1, 1, 3]}\n",
            "0.9720850454336694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3JZLsfcFxOd",
        "colab_type": "text"
      },
      "source": [
        "Well I think I have done enough for today and I'm pretty satisfied about the results that I obtained toda. Everything that is left is just make predictions with this model with the weights: [4,1,1,3]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfzk5obuGPoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "40451eae-4395-4f14-ebcd-746e17793a72"
      },
      "source": [
        "model = grid_Search.best_estimator_\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9719941363427603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-OX0VcEGhIM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "bb2bb64c-b664-4abd-cb7e-c88db6f9b210"
      },
      "source": [
        "model.fit(features,trainset.label)\n",
        "predictions = model.predict_proba(test_features)[:,1]\n",
        "\n",
        "sample_submission = pd.DataFrame({'index': testset['index'], 'label': predictions})\n",
        "sample_submission.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.011382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.453319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.014171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.992859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.959147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index     label\n",
              "0      0  0.011382\n",
              "1      1  0.453319\n",
              "2      2  0.014171\n",
              "3      3  0.992859\n",
              "4      4  0.959147"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "587aI3yHGt_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"my_prediction_results6_real.csv\"\n",
        "sample_submission.to_csv(filename,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}