{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blending/Stacking.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfrD8CzVDLdQSKZPA8ygo3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahGoddaer/Machine_Learning_course_UGent_D012554_kaggle/blob/master/7%3A%20Blending_Stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUoyn8UFLjqz",
        "colab_type": "text"
      },
      "source": [
        "Blending and stacking are two approaches, both of which deal with model assembly.\n",
        "\n",
        "In both blending and stacking, various prediction models are combined into one single prediction model, with the goal being to increase the prediction performance.\n",
        "\n",
        "They both train different models with the same training data, using the outputs as training data for a meta classifier to predict a final result.\n",
        "\n",
        "For example in binary classification, you train a SVM model or a decision tree. Then you can use the output of SVM and the decision tree to train a meta classifier such as logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phpANk68Yjqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "35cbfcfd-a375-48a9-fd59-601be44bfc9f"
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4PG2LeNYoRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "1d137929-a42f-4d7d-a8b4-cbe3c50c4e54"
      },
      "source": [
        "trainset = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/eeg_train.csv\")\n",
        "testset = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/eeg_test.csv\")\n",
        "\n",
        "features = trainset.copy()\n",
        "features.pop('label')\n",
        "feature_names = list(features.columns)\n",
        "\n",
        "test_features = testset.copy()\n",
        "test_features.pop('index')\n",
        "test_feature_names = list(test_features.columns)\n",
        "features.describe()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AF3</th>\n",
              "      <th>F7</th>\n",
              "      <th>F3</th>\n",
              "      <th>FC5</th>\n",
              "      <th>T7</th>\n",
              "      <th>P7</th>\n",
              "      <th>O1</th>\n",
              "      <th>02</th>\n",
              "      <th>P8</th>\n",
              "      <th>T8</th>\n",
              "      <th>FC6</th>\n",
              "      <th>F4</th>\n",
              "      <th>F8</th>\n",
              "      <th>AF4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4300.157125</td>\n",
              "      <td>4009.273150</td>\n",
              "      <td>4263.860860</td>\n",
              "      <td>4122.616195</td>\n",
              "      <td>4341.606870</td>\n",
              "      <td>4620.061720</td>\n",
              "      <td>4072.151250</td>\n",
              "      <td>4615.229300</td>\n",
              "      <td>4200.893915</td>\n",
              "      <td>4230.573235</td>\n",
              "      <td>4201.583060</td>\n",
              "      <td>4278.445325</td>\n",
              "      <td>4605.169335</td>\n",
              "      <td>4359.852780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>36.361719</td>\n",
              "      <td>29.853264</td>\n",
              "      <td>20.788323</td>\n",
              "      <td>20.565528</td>\n",
              "      <td>16.691038</td>\n",
              "      <td>18.034865</td>\n",
              "      <td>20.933632</td>\n",
              "      <td>18.391027</td>\n",
              "      <td>17.810272</td>\n",
              "      <td>19.661149</td>\n",
              "      <td>24.397269</td>\n",
              "      <td>19.645651</td>\n",
              "      <td>33.067591</td>\n",
              "      <td>37.074555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4197.950000</td>\n",
              "      <td>3905.640000</td>\n",
              "      <td>4202.560000</td>\n",
              "      <td>4058.460000</td>\n",
              "      <td>4310.260000</td>\n",
              "      <td>4569.740000</td>\n",
              "      <td>4032.820000</td>\n",
              "      <td>4571.280000</td>\n",
              "      <td>4147.690000</td>\n",
              "      <td>4158.970000</td>\n",
              "      <td>4107.180000</td>\n",
              "      <td>4216.410000</td>\n",
              "      <td>4454.360000</td>\n",
              "      <td>4225.640000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4280.510000</td>\n",
              "      <td>3990.770000</td>\n",
              "      <td>4250.260000</td>\n",
              "      <td>4108.720000</td>\n",
              "      <td>4331.790000</td>\n",
              "      <td>4611.790000</td>\n",
              "      <td>4057.440000</td>\n",
              "      <td>4604.100000</td>\n",
              "      <td>4190.260000</td>\n",
              "      <td>4219.490000</td>\n",
              "      <td>4189.740000</td>\n",
              "      <td>4267.180000</td>\n",
              "      <td>4590.642500</td>\n",
              "      <td>4342.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4293.330000</td>\n",
              "      <td>4006.150000</td>\n",
              "      <td>4262.560000</td>\n",
              "      <td>4121.030000</td>\n",
              "      <td>4338.460000</td>\n",
              "      <td>4617.950000</td>\n",
              "      <td>4069.740000</td>\n",
              "      <td>4612.820000</td>\n",
              "      <td>4199.490000</td>\n",
              "      <td>4228.720000</td>\n",
              "      <td>4200.000000</td>\n",
              "      <td>4276.410000</td>\n",
              "      <td>4603.080000</td>\n",
              "      <td>4354.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4309.740000</td>\n",
              "      <td>4023.590000</td>\n",
              "      <td>4270.260000</td>\n",
              "      <td>4133.460000</td>\n",
              "      <td>4347.180000</td>\n",
              "      <td>4626.150000</td>\n",
              "      <td>4083.590000</td>\n",
              "      <td>4623.080000</td>\n",
              "      <td>4209.230000</td>\n",
              "      <td>4238.970000</td>\n",
              "      <td>4211.280000</td>\n",
              "      <td>4286.150000</td>\n",
              "      <td>4617.950000</td>\n",
              "      <td>4371.790000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4497.440000</td>\n",
              "      <td>4152.820000</td>\n",
              "      <td>4385.640000</td>\n",
              "      <td>4234.360000</td>\n",
              "      <td>4452.820000</td>\n",
              "      <td>4754.870000</td>\n",
              "      <td>4174.870000</td>\n",
              "      <td>4731.280000</td>\n",
              "      <td>4315.380000</td>\n",
              "      <td>4352.310000</td>\n",
              "      <td>4325.640000</td>\n",
              "      <td>4397.950000</td>\n",
              "      <td>4796.920000</td>\n",
              "      <td>4538.970000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               AF3           F7  ...           F8          AF4\n",
              "count  2000.000000  2000.000000  ...  2000.000000  2000.000000\n",
              "mean   4300.157125  4009.273150  ...  4605.169335  4359.852780\n",
              "std      36.361719    29.853264  ...    33.067591    37.074555\n",
              "min    4197.950000  3905.640000  ...  4454.360000  4225.640000\n",
              "25%    4280.510000  3990.770000  ...  4590.642500  4342.050000\n",
              "50%    4293.330000  4006.150000  ...  4603.080000  4354.360000\n",
              "75%    4309.740000  4023.590000  ...  4617.950000  4371.790000\n",
              "max    4497.440000  4152.820000  ...  4796.920000  4538.970000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Wncs8IHL3RR",
        "colab_type": "text"
      },
      "source": [
        "#Creating ensembles from submisstion files.\n",
        "\n",
        "The most basic and convenient way to ensemble is to ensemble Kaggle submission CSV files. You only need the predictions on the test set for these methods â€” no need to retrain a model. This makes it a quick way to ensemble already existing model predictions, ideal when teaming up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez0jJnYfM62y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "estimators = [('SVC',make_pipeline(StandardScaler(),\n",
        "                                   SVC(C=10,gamma=1, probability=True))),\n",
        "              ('rf', RandomForestClassifier(criterion='entropy',\n",
        "                                            n_estimators=250, max_depth=30, \n",
        "                                            bootstrap=True)),\n",
        "               ('boost', XGBClassifier(n_estimators= 900, gamma=0,\n",
        "                                       max_depth=7, min_child_weight=0,\n",
        "                                       learning_rate=0.1, subsample=0.85,\n",
        "                                       colsample_bytree=0.9)),]\n",
        "\n",
        "clf = StackingClassifier(estimators=estimators, \n",
        "                         final_estimator=LogisticRegression(),cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aV4oXMuTjCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "18ff1656-2ea1-4222-f094-f2228981b323"
      },
      "source": [
        "model = clf\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9681853589835242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_kiqKnRbXiN",
        "colab_type": "text"
      },
      "source": [
        "Yes, this actually gives my highest cross-validation score until now, so I'm going to upload predictions from this model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zylLB6M7Y1jG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7bda7b91-21c6-4beb-c178-762070309b2e"
      },
      "source": [
        "model.fit(features,trainset.label)\n",
        "predictions = model.predict_proba(test_features)[:,1]\n",
        "\n",
        "sample_submission = pd.DataFrame({'index': testset['index'], 'label': predictions})\n",
        "sample_submission.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.023330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.191001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.023217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.981099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.972256</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index     label\n",
              "0      0  0.023330\n",
              "1      1  0.191001\n",
              "2      2  0.023217\n",
              "3      3  0.981099\n",
              "4      4  0.972256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBgmEGiUbrwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"my_prediction_results5.csv\"\n",
        "sample_submission.to_csv(filename,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5TbntGwd_UB",
        "colab_type": "text"
      },
      "source": [
        "I can explore this new technique a little bit further, engaging other models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mLY9VVCfUlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimators = [('SVC',make_pipeline(StandardScaler(),\n",
        "                                   SVC(C=10,gamma=1, probability=True))),\n",
        "              ('rf', RandomForestClassifier(criterion='entropy',\n",
        "                                            n_estimators=250, max_depth=30, \n",
        "                                            bootstrap=True)),\n",
        "               ('boost', XGBClassifier(n_estimators= 900, gamma=0,\n",
        "                                       max_depth=7, min_child_weight=0,\n",
        "                                       learning_rate=0.1, subsample=0.85,\n",
        "                                       colsample_bytree=0.9)),\n",
        "              ('regression', make_pipeline(StandardScaler(),\n",
        "                                           LogisticRegression(C=100)))]\n",
        "\n",
        "clf = StackingClassifier(estimators=estimators, \n",
        "                         final_estimator=LogisticRegression(),cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEmvJdh6exJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "18191408-a578-47c8-a34c-b89db07677aa"
      },
      "source": [
        "model = clf\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9675489759985172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDVV7xg5gTb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimators = [('SVC',make_pipeline(StandardScaler(),\n",
        "                                   SVC(C=10,gamma=1, probability=True))),\n",
        "              ('rf', RandomForestClassifier(criterion='entropy',\n",
        "                                            n_estimators=250, max_depth=30, \n",
        "                                            bootstrap=True)),\n",
        "               ('boost', XGBClassifier(n_estimators= 900, gamma=0,\n",
        "                                       max_depth=7, min_child_weight=0,\n",
        "                                       learning_rate=0.1, subsample=0.85,\n",
        "                                       colsample_bytree=0.9)),\n",
        "              ('regression', make_pipeline(StandardScaler(),\n",
        "                                           LogisticRegression(C=100)))]\n",
        "\n",
        "clf = StackingClassifier(estimators=estimators, \n",
        "                         final_estimator=SVC(),cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSfb02h_hL5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8d2b6d03-8f76-4f68-ce54-47ec505dc8f6"
      },
      "source": [
        "model = clf\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9312414751405577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4QKjb8DjCje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "estimators = [('SVC',make_pipeline(StandardScaler(),\n",
        "                                   SVC(C=10,gamma=1, probability=True))),\n",
        "              ('rf', RandomForestClassifier(criterion='entropy',\n",
        "                                            n_estimators=250, max_depth=30, \n",
        "                                            bootstrap=True)),\n",
        "               ('boost', XGBClassifier(n_estimators= 900, gamma=0,\n",
        "                                       max_depth=7, min_child_weight=0,\n",
        "                                       learning_rate=0.1, subsample=0.85,\n",
        "                                       colsample_bytree=0.9)),\n",
        "              ('neighbors', KNeighborsClassifier(n_neighbors=4,\n",
        "                                                 weights='distance')),\n",
        "              ('regression', make_pipeline(StandardScaler(),\n",
        "                                           LogisticRegression(C=100)))]\n",
        "\n",
        "clf = StackingClassifier(estimators=estimators, \n",
        "                         final_estimator=LogisticRegression(),cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4CQkey-o5G7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ebd8e6cb-bebf-4ef6-d0c5-a949492b3534"
      },
      "source": [
        "model = clf\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9716507406966123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKO2uSkysJLe",
        "colab_type": "text"
      },
      "source": [
        "With the addition of the KNeighborsClassifier, this is the highest score now, so I'm going to try to upload predictions with this model later on today I think."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J0oPh2pwDmH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2c8dddbd-0e77-4ba9-bb40-6778a2218446"
      },
      "source": [
        "model.fit(features,trainset.label)\n",
        "predictions = model.predict_proba(test_features)[:,1]\n",
        "\n",
        "sample_submission = pd.DataFrame({'index': testset['index'], 'label': predictions})\n",
        "sample_submission.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.019745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.437415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.020058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.984825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.979247</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index     label\n",
              "0      0  0.019745\n",
              "1      1  0.437415\n",
              "2      2  0.020058\n",
              "3      3  0.984825\n",
              "4      4  0.979247"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6VkPNsowK4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"my_prediction_results6.csv\"\n",
        "sample_submission.to_csv(filename,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkcx7-Bgsdna",
        "colab_type": "text"
      },
      "source": [
        "First, I'm going to figure out if I could exploit this technique a bit more and try to push it just a bit further:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TUYkA8ywCrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "estimators = [('SVC',make_pipeline(StandardScaler(),\n",
        "                                   SVC(C=10,gamma=1, probability=True))),\n",
        "              ('rf', RandomForestClassifier(criterion='entropy',\n",
        "                                            n_estimators=250, max_depth=30, \n",
        "                                            bootstrap=True)),\n",
        "               ('boost', XGBClassifier(n_estimators= 900, gamma=0,\n",
        "                                       max_depth=7, min_child_weight=0,\n",
        "                                       learning_rate=0.1, subsample=0.85,\n",
        "                                       colsample_bytree=0.9)),\n",
        "              ('neighbors', KNeighborsClassifier(n_neighbors=4,\n",
        "                                                 weights='distance')),\n",
        "              ('tree', DecisionTreeClassifier(max_depth=8,\n",
        "                                              criterion = 'entropy')),\n",
        "              ('regression', make_pipeline(StandardScaler(),\n",
        "                                           LogisticRegression(C=100)))]\n",
        "\n",
        "clf = StackingClassifier(estimators=estimators, \n",
        "                         final_estimator=LogisticRegression(),cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYKMzfRixyLV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "53b7dd7b-e9cc-4ecd-e27c-5de33de152d6"
      },
      "source": [
        "model = clf\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9712471840086521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Xybvw90lFz",
        "colab_type": "text"
      },
      "source": [
        "Nope, this was no succes.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bZbmWvrx0bs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}