{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blending/Stacking.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJAFxBlFL92wCG+1Xa135N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahGoddaer/Machine_Learning_course_UGent_D012554_kaggle/blob/master/7%3A%20Blending_Stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUoyn8UFLjqz",
        "colab_type": "text"
      },
      "source": [
        "Blending and **stacking** are two approaches, both of which deal with model assembly.\n",
        "\n",
        "In both blending and stacking, various prediction models are combined into one single prediction model, with the goal being to increase the prediction performance.\n",
        "\n",
        "They both train different models with the same training data, using the outputs as training data for a meta classifier to predict a final result.\n",
        "\n",
        "For example in binary classification, you train a SVM model or a decision tree. Then you can use the output of SVM and the decision tree to train a meta classifier such as logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phpANk68Yjqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f181003c-94d1-4ac8-b356-b450081d1d4c"
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4PG2LeNYoRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7314b28b-0f0e-46fc-8720-803353d17ae5"
      },
      "source": [
        "trainset = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/eeg_train.csv\")\n",
        "testset = pd.read_csv(\"https://raw.githubusercontent.com/sdgroeve/Machine_Learning_course_UGent_D012554_kaggle/master/eeg_test.csv\")\n",
        "\n",
        "features = trainset.copy()\n",
        "features.pop('label')\n",
        "feature_names = list(features.columns)\n",
        "\n",
        "test_features = testset.copy()\n",
        "test_features.pop('index')\n",
        "test_feature_names = list(test_features.columns)\n",
        "features.describe()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AF3</th>\n",
              "      <th>F7</th>\n",
              "      <th>F3</th>\n",
              "      <th>FC5</th>\n",
              "      <th>T7</th>\n",
              "      <th>P7</th>\n",
              "      <th>O1</th>\n",
              "      <th>02</th>\n",
              "      <th>P8</th>\n",
              "      <th>T8</th>\n",
              "      <th>FC6</th>\n",
              "      <th>F4</th>\n",
              "      <th>F8</th>\n",
              "      <th>AF4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "      <td>2000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4300.157125</td>\n",
              "      <td>4009.273150</td>\n",
              "      <td>4263.860860</td>\n",
              "      <td>4122.616195</td>\n",
              "      <td>4341.606870</td>\n",
              "      <td>4620.061720</td>\n",
              "      <td>4072.151250</td>\n",
              "      <td>4615.229300</td>\n",
              "      <td>4200.893915</td>\n",
              "      <td>4230.573235</td>\n",
              "      <td>4201.583060</td>\n",
              "      <td>4278.445325</td>\n",
              "      <td>4605.169335</td>\n",
              "      <td>4359.852780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>36.361719</td>\n",
              "      <td>29.853264</td>\n",
              "      <td>20.788323</td>\n",
              "      <td>20.565528</td>\n",
              "      <td>16.691038</td>\n",
              "      <td>18.034865</td>\n",
              "      <td>20.933632</td>\n",
              "      <td>18.391027</td>\n",
              "      <td>17.810272</td>\n",
              "      <td>19.661149</td>\n",
              "      <td>24.397269</td>\n",
              "      <td>19.645651</td>\n",
              "      <td>33.067591</td>\n",
              "      <td>37.074555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4197.950000</td>\n",
              "      <td>3905.640000</td>\n",
              "      <td>4202.560000</td>\n",
              "      <td>4058.460000</td>\n",
              "      <td>4310.260000</td>\n",
              "      <td>4569.740000</td>\n",
              "      <td>4032.820000</td>\n",
              "      <td>4571.280000</td>\n",
              "      <td>4147.690000</td>\n",
              "      <td>4158.970000</td>\n",
              "      <td>4107.180000</td>\n",
              "      <td>4216.410000</td>\n",
              "      <td>4454.360000</td>\n",
              "      <td>4225.640000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4280.510000</td>\n",
              "      <td>3990.770000</td>\n",
              "      <td>4250.260000</td>\n",
              "      <td>4108.720000</td>\n",
              "      <td>4331.790000</td>\n",
              "      <td>4611.790000</td>\n",
              "      <td>4057.440000</td>\n",
              "      <td>4604.100000</td>\n",
              "      <td>4190.260000</td>\n",
              "      <td>4219.490000</td>\n",
              "      <td>4189.740000</td>\n",
              "      <td>4267.180000</td>\n",
              "      <td>4590.642500</td>\n",
              "      <td>4342.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4293.330000</td>\n",
              "      <td>4006.150000</td>\n",
              "      <td>4262.560000</td>\n",
              "      <td>4121.030000</td>\n",
              "      <td>4338.460000</td>\n",
              "      <td>4617.950000</td>\n",
              "      <td>4069.740000</td>\n",
              "      <td>4612.820000</td>\n",
              "      <td>4199.490000</td>\n",
              "      <td>4228.720000</td>\n",
              "      <td>4200.000000</td>\n",
              "      <td>4276.410000</td>\n",
              "      <td>4603.080000</td>\n",
              "      <td>4354.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4309.740000</td>\n",
              "      <td>4023.590000</td>\n",
              "      <td>4270.260000</td>\n",
              "      <td>4133.460000</td>\n",
              "      <td>4347.180000</td>\n",
              "      <td>4626.150000</td>\n",
              "      <td>4083.590000</td>\n",
              "      <td>4623.080000</td>\n",
              "      <td>4209.230000</td>\n",
              "      <td>4238.970000</td>\n",
              "      <td>4211.280000</td>\n",
              "      <td>4286.150000</td>\n",
              "      <td>4617.950000</td>\n",
              "      <td>4371.790000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4497.440000</td>\n",
              "      <td>4152.820000</td>\n",
              "      <td>4385.640000</td>\n",
              "      <td>4234.360000</td>\n",
              "      <td>4452.820000</td>\n",
              "      <td>4754.870000</td>\n",
              "      <td>4174.870000</td>\n",
              "      <td>4731.280000</td>\n",
              "      <td>4315.380000</td>\n",
              "      <td>4352.310000</td>\n",
              "      <td>4325.640000</td>\n",
              "      <td>4397.950000</td>\n",
              "      <td>4796.920000</td>\n",
              "      <td>4538.970000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               AF3           F7  ...           F8          AF4\n",
              "count  2000.000000  2000.000000  ...  2000.000000  2000.000000\n",
              "mean   4300.157125  4009.273150  ...  4605.169335  4359.852780\n",
              "std      36.361719    29.853264  ...    33.067591    37.074555\n",
              "min    4197.950000  3905.640000  ...  4454.360000  4225.640000\n",
              "25%    4280.510000  3990.770000  ...  4590.642500  4342.050000\n",
              "50%    4293.330000  4006.150000  ...  4603.080000  4354.360000\n",
              "75%    4309.740000  4023.590000  ...  4617.950000  4371.790000\n",
              "max    4497.440000  4152.820000  ...  4796.920000  4538.970000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Wncs8IHL3RR",
        "colab_type": "text"
      },
      "source": [
        "#Creating ensembles from submisstion files.\n",
        "\n",
        "The most basic and convenient way to ensemble is to ensemble Kaggle submission CSV files. You only need the predictions on the test set for these methods — no need to retrain a model. This makes it a quick way to ensemble already existing model predictions, ideal when teaming up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez0jJnYfM62y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "estimators = [('SVC',make_pipeline(StandardScaler(),\n",
        "                                   SVC(C=10,gamma=1, probability=True))),\n",
        "              ('rf', RandomForestClassifier(criterion='entropy',\n",
        "                                            n_estimators=250, max_depth=30, \n",
        "                                            bootstrap=True)),\n",
        "               ('boost', XGBClassifier(n_estimators= 900, gamma=0,\n",
        "                                       max_depth=7, min_child_weight=0,\n",
        "                                       learning_rate=0.1, subsample=0.85,\n",
        "                                       colsample_bytree=0.9)),]\n",
        "\n",
        "clf = StackingClassifier(estimators=estimators, \n",
        "                         final_estimator=LogisticRegression(),cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aV4oXMuTjCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "18ff1656-2ea1-4222-f094-f2228981b323"
      },
      "source": [
        "model = clf\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9681853589835242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_kiqKnRbXiN",
        "colab_type": "text"
      },
      "source": [
        "Yes, this actually gives my highest cross-validation score until now, so I'm going to upload predictions from this model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zylLB6M7Y1jG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7bda7b91-21c6-4beb-c178-762070309b2e"
      },
      "source": [
        "model.fit(features,trainset.label)\n",
        "predictions = model.predict_proba(test_features)[:,1]\n",
        "\n",
        "sample_submission = pd.DataFrame({'index': testset['index'], 'label': predictions})\n",
        "sample_submission.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.023330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.191001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.023217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.981099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.972256</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index     label\n",
              "0      0  0.023330\n",
              "1      1  0.191001\n",
              "2      2  0.023217\n",
              "3      3  0.981099\n",
              "4      4  0.972256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBgmEGiUbrwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"my_prediction_results5.csv\"\n",
        "sample_submission.to_csv(filename,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5TbntGwd_UB",
        "colab_type": "text"
      },
      "source": [
        "I can explore this new technique a little bit further, engaging other models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mLY9VVCfUlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimators = [('SVC',make_pipeline(StandardScaler(),\n",
        "                                   SVC(C=10,gamma=1, probability=True))),\n",
        "              ('rf', RandomForestClassifier(criterion='entropy',\n",
        "                                            n_estimators=250, max_depth=30, \n",
        "                                            bootstrap=True)),\n",
        "               ('boost', XGBClassifier(n_estimators= 900, gamma=0,\n",
        "                                       max_depth=7, min_child_weight=0,\n",
        "                                       learning_rate=0.1, subsample=0.85,\n",
        "                                       colsample_bytree=0.9)),\n",
        "              ('regression', make_pipeline(StandardScaler(),\n",
        "                                           LogisticRegression(C=100)))]\n",
        "\n",
        "clf = StackingClassifier(estimators=estimators, \n",
        "                         final_estimator=LogisticRegression(),cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEmvJdh6exJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "18191408-a578-47c8-a34c-b89db07677aa"
      },
      "source": [
        "model = clf\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9675489759985172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDVV7xg5gTb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimators = [('SVC',make_pipeline(StandardScaler(),\n",
        "                                   SVC(C=10,gamma=1, probability=True))),\n",
        "              ('rf', RandomForestClassifier(criterion='entropy',\n",
        "                                            n_estimators=250, max_depth=30, \n",
        "                                            bootstrap=True)),\n",
        "               ('boost', XGBClassifier(n_estimators= 900, gamma=0,\n",
        "                                       max_depth=7, min_child_weight=0,\n",
        "                                       learning_rate=0.1, subsample=0.85,\n",
        "                                       colsample_bytree=0.9)),\n",
        "              ('regression', make_pipeline(StandardScaler(),\n",
        "                                           LogisticRegression(C=100)))]\n",
        "\n",
        "clf = StackingClassifier(estimators=estimators, \n",
        "                         final_estimator=SVC(),cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSfb02h_hL5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8d2b6d03-8f76-4f68-ce54-47ec505dc8f6"
      },
      "source": [
        "model = clf\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9312414751405577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4QKjb8DjCje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "estimators = [('SVC',make_pipeline(StandardScaler(),\n",
        "                                   SVC(C=10,gamma=1, probability=True))),\n",
        "              ('rf', RandomForestClassifier(criterion='entropy',\n",
        "                                            n_estimators=250, max_depth=30, \n",
        "                                            bootstrap=True)),\n",
        "               ('boost', XGBClassifier(n_estimators= 900, gamma=0,\n",
        "                                       max_depth=7, min_child_weight=0,\n",
        "                                       learning_rate=0.1, subsample=0.85,\n",
        "                                       colsample_bytree=0.9)),\n",
        "              ('neighbors', KNeighborsClassifier(n_neighbors=4,\n",
        "                                                 weights='distance')),\n",
        "              ('regression', make_pipeline(StandardScaler(),\n",
        "                                           LogisticRegression(C=100)))]\n",
        "\n",
        "Stack = StackingClassifier(estimators=estimators, \n",
        "                         final_estimator=LogisticRegression(),cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4CQkey-o5G7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ebd8e6cb-bebf-4ef6-d0c5-a949492b3534"
      },
      "source": [
        "model = clf\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9716507406966123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKO2uSkysJLe",
        "colab_type": "text"
      },
      "source": [
        "With the addition of the KNeighborsClassifier, this is the highest score now, so I'm going to try to upload predictions with this model later on today I think."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J0oPh2pwDmH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2c8dddbd-0e77-4ba9-bb40-6778a2218446"
      },
      "source": [
        "model.fit(features,trainset.label)\n",
        "predictions = model.predict_proba(test_features)[:,1]\n",
        "\n",
        "sample_submission = pd.DataFrame({'index': testset['index'], 'label': predictions})\n",
        "sample_submission.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.019745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.437415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.020058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.984825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.979247</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index     label\n",
              "0      0  0.019745\n",
              "1      1  0.437415\n",
              "2      2  0.020058\n",
              "3      3  0.984825\n",
              "4      4  0.979247"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6VkPNsowK4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"my_prediction_results6.csv\" #FOR THE 6th ATTEMPT LOOK AT NOTEBOOK 9: VOTING CLASSIFIER FOR \"my_prediction_results6_real.csv\"\n",
        "sample_submission.to_csv(filename,index=False) #THIS IS ACTUALLY THE 7th ATTEMPT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDQH8e4u4kdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "2d005c36-693e-4d39-afbc-d19ff39070d5"
      },
      "source": [
        "clf.final_estimator"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkcx7-Bgsdna",
        "colab_type": "text"
      },
      "source": [
        "First, I'm going to figure out if I could exploit this technique a bit more and try to push it just a bit further:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TUYkA8ywCrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "estimators = [('SVC',make_pipeline(StandardScaler(),\n",
        "                                   SVC(C=10,gamma=1, probability=True))),\n",
        "              ('rf', RandomForestClassifier(criterion='entropy',\n",
        "                                            n_estimators=250, max_depth=30, \n",
        "                                            bootstrap=True)),\n",
        "               ('boost', XGBClassifier(n_estimators= 900, gamma=0,\n",
        "                                       max_depth=7, min_child_weight=0,\n",
        "                                       learning_rate=0.1, subsample=0.85,\n",
        "                                       colsample_bytree=0.9)),\n",
        "              ('neighbors', KNeighborsClassifier(n_neighbors=4,\n",
        "                                                 weights='distance')),\n",
        "              ('tree', DecisionTreeClassifier(max_depth=8,\n",
        "                                              criterion = 'entropy')),\n",
        "              ('regression', make_pipeline(StandardScaler(),\n",
        "                                           LogisticRegression(C=100)))]\n",
        "\n",
        "clf = StackingClassifier(estimators=estimators, \n",
        "                         final_estimator=LogisticRegression(),cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYKMzfRixyLV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "53b7dd7b-e9cc-4ecd-e27c-5de33de152d6"
      },
      "source": [
        "model = clf\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9712471840086521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Xybvw90lFz",
        "colab_type": "text"
      },
      "source": [
        "Nope, this was no succes.. Back to the other model with score 0.9716."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQpma_GIZniY",
        "colab_type": "text"
      },
      "source": [
        "Maybe we can try a **voting classifier**, which also includes this stacking model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bZbmWvrx0bs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Training classifiers\n",
        "clf1 = make_pipeline(StandardScaler(), SVC(C=10,gamma=1, probability=True))\n",
        "clf2 = RandomForestClassifier(criterion='entropy', n_estimators=250, \n",
        "                              max_depth=30, random_state=0)\n",
        "clf3 = XGBClassifier(n_estimators= 900, gamma=0, max_depth=7, \n",
        "                     min_child_weight=0, learning_rate=0.1, \n",
        "                     subsample=0.85, colsample_bytree=0.9)\n",
        "clf4 = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
        "clf5 = make_pipeline(StandardScaler(),LogisticRegression(C=100))\n",
        "clf6 = Stack\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), \n",
        "                                    ('xgb', clf3), ('kkn', clf4), \n",
        "                                    ('reg', clf5), ('stack', clf6)]\n",
        "                        , voting='soft')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En8Ax_PPZY5S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "626b5386-abcb-4511-80f9-df3b5b384e62"
      },
      "source": [
        "for clf, name in zip([clf1, clf2, clf3, clf4, clf5, clf6, eclf], \n",
        "                      ['SVC', 'Random Forest', 'XGBoost', 'KNeighbors', \n",
        "                       'Logistic regression', 'stack', 'Ensemble']):\n",
        "  scores = cross_val_score(clf, features, trainset.label, \n",
        "                           scoring='roc_auc', cv=10)\n",
        "  print(\"AUC score: %0.5f (+/- %0.5f) [%s]\" % (scores.mean(), scores.std(), name))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score: 0.96253 (+/- 0.01182) [SVC]\n",
            "AUC score: 0.93205 (+/- 0.01971) [Random Forest]\n",
            "AUC score: 0.94602 (+/- 0.02002) [XGBoost]\n",
            "AUC score: 0.95938 (+/- 0.01119) [KNeighbors]\n",
            "AUC score: 0.65963 (+/- 0.03643) [Logistic regression]\n",
            "AUC score: 0.97165 (+/- 0.01089) [stack]\n",
            "AUC score: 0.96852 (+/- 0.01331) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrcFpgqTfj1I",
        "colab_type": "text"
      },
      "source": [
        "Ohn, this doesn't seem to have a better performance than the stacked model.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIy9pSSudpFm",
        "colab_type": "text"
      },
      "source": [
        "I try to assign some weights on the different submodels, just to try out and see what a difference it makes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q0UfNDBZl61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "1612d762-ab54-4ba5-fe83-179224e20d0d"
      },
      "source": [
        "votingClass = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), \n",
        "                                    ('xgb', clf3), ('kkn', clf4), \n",
        "                                    ('reg', clf5), ('stack', clf6)]\n",
        "                        , voting='soft', weights=[2,1,1,2,1,2])\n",
        "\n",
        "for clf, name in zip([clf1, clf2, clf3, clf4, clf5, clf6, votingClass], \n",
        "                      ['SVC', 'Random Forest', 'XGBoost', 'KNeighbors', \n",
        "                       'Logistic regression', 'stack', 'Ensemble']):\n",
        "  scores = cross_val_score(clf, features, trainset.label, \n",
        "                           scoring='roc_auc', cv=10)\n",
        "  print(\"AUC score: %0.5f (+/- %0.5f) [%s]\" % (scores.mean(), scores.std(), name))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score: 0.96253 (+/- 0.01182) [SVC]\n",
            "AUC score: 0.93205 (+/- 0.01971) [Random Forest]\n",
            "AUC score: 0.94602 (+/- 0.02002) [XGBoost]\n",
            "AUC score: 0.95938 (+/- 0.01119) [KNeighbors]\n",
            "AUC score: 0.65963 (+/- 0.03643) [Logistic regression]\n",
            "AUC score: 0.97163 (+/- 0.01101) [stack]\n",
            "AUC score: 0.97092 (+/- 0.01219) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmoT-AcgkYaP",
        "colab_type": "text"
      },
      "source": [
        "This doesn't work as good as I thought."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOGGmU5Bkcm2",
        "colab_type": "text"
      },
      "source": [
        "If I now do exactly the same without the logistic regression model, once without assigned weights and once with them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euE6J6mymzrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "estimators = [('SVC',make_pipeline(StandardScaler(),\n",
        "                                   SVC(C=10,gamma=1, probability=True))),\n",
        "              ('rf', RandomForestClassifier(criterion='entropy',\n",
        "                                            n_estimators=250, max_depth=30, \n",
        "                                            bootstrap=True)),\n",
        "               ('boost', XGBClassifier(n_estimators= 900, gamma=0,\n",
        "                                       max_depth=7, min_child_weight=0,\n",
        "                                       learning_rate=0.1, subsample=0.85,\n",
        "                                       colsample_bytree=0.9)),\n",
        "              ('neighbors', KNeighborsClassifier(n_neighbors=4,\n",
        "                                                 weights='distance')),\n",
        "              ('tree', DecisionTreeClassifier(max_depth=8,\n",
        "                                              criterion = 'entropy'))]\n",
        "\n",
        "stack = StackingClassifier(estimators=estimators, \n",
        "                         final_estimator=LogisticRegression(),cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLAvq4BJnYgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7ff160e4-798e-430d-868a-d37df7c3ab42"
      },
      "source": [
        "model = stack\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score for trainset: 0.9713378222185562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMkZqWvTnl3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf1 = make_pipeline(StandardScaler(), SVC(C=10,gamma=1, probability=True))\n",
        "clf2 = RandomForestClassifier(criterion='entropy', n_estimators=250, \n",
        "                              max_depth=30, random_state=0)\n",
        "clf3 = XGBClassifier(n_estimators= 900, gamma=0, max_depth=7, \n",
        "                     min_child_weight=0, learning_rate=0.1, \n",
        "                     subsample=0.85, colsample_bytree=0.9)\n",
        "clf4 = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
        "clf5 = Stack\n",
        "\n",
        "vote = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), \n",
        "                                    ('xgb', clf3), ('kkn', clf4), \n",
        "                                    ('stack', clf5)]\n",
        "                        , voting='soft')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kJKuFC8ny_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "8ffce4d7-c04f-42fc-addb-43e001536192"
      },
      "source": [
        "for clf, name in zip([clf1, clf2, clf3, clf4, clf5, vote], \n",
        "                      ['SVC', 'Random Forest', 'XGBoost', 'KNeighbors',\n",
        "                       'stack', 'Ensemble']):\n",
        "  scores = cross_val_score(clf, features, trainset.label, \n",
        "                           scoring='roc_auc', cv=10)\n",
        "  print(\"AUC score: %0.5f (+/- %0.5f) [%s]\" % (scores.mean(), scores.std(), name))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score: 0.96253 (+/- 0.01182) [SVC]\n",
            "AUC score: 0.93205 (+/- 0.01971) [Random Forest]\n",
            "AUC score: 0.94602 (+/- 0.02002) [XGBoost]\n",
            "AUC score: 0.95938 (+/- 0.01119) [KNeighbors]\n",
            "AUC score: 0.97149 (+/- 0.01084) [stack]\n",
            "AUC score: 0.97042 (+/- 0.01146) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YKIGOjJn-_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "cda695ed-5974-4e26-b709-746a3440f682"
      },
      "source": [
        "votingClass = VotingClassifier(estimators=[('svc', clf1), ('rf', clf2), \n",
        "                                    ('xgb', clf3), ('kkn', clf4), \n",
        "                                    ('stack', clf5)], \n",
        "                               voting='soft', weights=[2,1,1,2,2])\n",
        "\n",
        "for clf, name in zip([clf1, clf2, clf3, clf4, clf5, votingClass], \n",
        "                      ['SVC', 'Random Forest', 'XGBoost', 'KNeighbors'\n",
        "                      , 'stack', 'Ensemble']):\n",
        "  scores = cross_val_score(clf, features, trainset.label, \n",
        "                           scoring='roc_auc', cv=10)\n",
        "  print(\"AUC score: %0.5f (+/- %0.5f) [%s]\" % (scores.mean(), scores.std(), name))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score: 0.96253 (+/- 0.01182) [SVC]\n",
            "AUC score: 0.93205 (+/- 0.01971) [Random Forest]\n",
            "AUC score: 0.94602 (+/- 0.02002) [XGBoost]\n",
            "AUC score: 0.95938 (+/- 0.01119) [KNeighbors]\n",
            "AUC score: 0.97152 (+/- 0.01082) [stack]\n",
            "AUC score: 0.97160 (+/- 0.01114) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3OG8RMqoh3h",
        "colab_type": "text"
      },
      "source": [
        "Now I will look for a certain choice of the weights..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjvxaFFof-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b957b199-2ae8-43b3-d0b5-cbc6203b1488"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {'weights':[[2,1,1,2,2],[3,1,2,3,3],[3,1,2,2,3],[2,1,1,2,3]]}\n",
        "grid_Search = GridSearchCV(param_grid = params, estimator=vote, scoring='roc_auc', cv=10)\n",
        "grid_Search.fit(features, trainset.label)\n",
        "grid_Search.best_params_\n",
        "grid_Search.best_score_"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9717210607944555"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mvzqyKUJ_B8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = grid_Search.best_estimator_\n",
        "score = cross_val_score(model, features, trainset.label,scoring='roc_auc', cv= 10).mean()\n",
        "print('AUC score for trainset: '+ str(score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_WdIx1EIxJ5",
        "colab_type": "text"
      },
      "source": [
        "Well...for this notebook I've had a lot of patience. Nevertheless, these results were not as good as the one I eventually obtained in the 9th notebook. However, this seems also a very good technique."
      ]
    }
  ]
}